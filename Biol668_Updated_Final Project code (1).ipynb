{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb95dac-dbe0-4a79-9c32-5f49a874da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openpyxl import load_workbook\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f965ffa-721e-459a-bb0d-122a4e6e4ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bsaucedo0075\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1d12f8c-a845-4bcd-b490-4725371b9bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = pd.ExcelFile('C:/Users/bsaucedo0075/Desktop/RawBlog_20250125.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a49686e2-aea7-48b0-8256-31c37a55afb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T7 P4 N', 'T7 P3 N', 'T7 P2 N', 'T7 P1 N', 'T7 P4 C2', 'T7 P3 C2', 'T7 P2 C2', 'T7 P1 C2', 'T7 P4 C1', 'T7 P3 C1', 'T7 P2 C1', 'T7 P1 C1', 'T6 P4 N', 'T6 P3 N', 'T6 P2 N', 'T6 P1 N', 'T6 P4 C2', 'T6 P3 C2', 'T6 P2 C2', 'T6 P1 C2', 'T6 P4 C1', 'T6 P3 C1', 'T6 P2 C1', 'T6 P1 C1', 'T5 P4 N', 'T5 P3 N', 'T5 P2 N', 'T5 P1 N', 'T5 P4 C2', 'T5 P3 C2', 'T5 P2 C2', 'T5 P1 C2', 'T5 P4 C1', 'T5 P3 C1', 'T5 P2 C1', 'T5 P1 C1', 'T4 P4 N', 'T4 P3 N', 'T4 P2 N', 'T4 P1 N', 'T4 P4 C2', 'T4 P3 C2', 'T4 P2 C2', 'T4 P1 C2', 'T4 P4 C1', 'T4 P3 C1', 'T4 P2 C1', 'T4 P1 C1', 'T3 P4 N', 'T3 P3 N', 'T3 P2 N', 'T3 P1 N', 'T3 P4 C2', 'T3 P3 C2', 'T3 P2 C2', 'T3 P1 C2', 'T3 P4 C1', 'T3 P3 C1', 'T3 P2 C1', 'T3 P1 C1', 'T2 P4 N', 'T2 P3 N', 'T2 P2 N', 'T2 P1 N', 'T2 P4 C2', 'T2 P3 C2', 'T2 P2 C2', 'T2 P1 C2', 'T2 P4 C1', 'T2 P2 C1', 'T2 P1 C1', 'T2 P3 C1', 'T1 P4 N', 'T1 P3 N', 'T1 P2 N', 'T1 P1 N', 'T1 P4 C2', 'T1 P3 C2', 'T1 P2 C2', 'T1 P1 C2', 'T1 P3 C1', 'T1 P2 C1', 'T1 P1 C1', 'T1 P4 C1', 'T0 P4 C1', 'T0 P3 C1', 'T0 P2 C1', 'T0 P1 C1', 'T0 P4 C2', 'T0 P3 C2', 'T0 P2 C2', 'T0 P1 C2', 'T0 P4 N', 'T0 P3 N', 'T0 P2 N', 'T0 P1 N']\n"
     ]
    }
   ],
   "source": [
    "print(excel_file.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ff3b233-8df1-4af3-844c-055808f3e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_sheets = {'C1': [], 'C2': [], 'N': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78ab8bb9-b599-4ce1-b187-b85049c73c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1 saved to C:/Users/bsaucedo0075/Desktop/C1_combined.xlsx\n",
      "C2 saved to C:/Users/bsaucedo0075/Desktop/C2_combined.xlsx\n",
      "N saved to C:/Users/bsaucedo0075/Desktop/N_combined.xlsx\n"
     ]
    }
   ],
   "source": [
    "for sheet in excel_file.sheet_names:\n",
    "    parts = sheet.split()\n",
    "    if len(parts) == 3:\n",
    "        condition = parts[2]\n",
    "        if condition in condition_sheets:\n",
    "            condition_sheets[condition].append(sheet)\n",
    "\n",
    "for condition, sheets in condition_sheets.items():\n",
    "    output_path = f'C:/Users/bsaucedo0075/Desktop/{condition}_combined.xlsx'\n",
    "    with pd.ExcelWriter(output_path) as writer:\n",
    "        for sheet in sheets:\n",
    "            df = excel_file.parse(sheet)\n",
    "            df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "        print(f\"{condition} saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3fc8f8f-6bf2-4e4e-8534-dda5487ee2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = 'C1'\n",
    "file_path = f'C:/Users/bsaucedo0075/Desktop/{condition}_combined.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5483f8d0-7306-4ee5-b483-426579e159e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = pd.ExcelFile(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbf63f68-418a-4770-b297-7eed0c66ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = pd.ExcelFile(file_path, engine='openpyxl')\n",
    "volume_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f7a5f62-7fd3-4ac7-8fda-2eea1aaea70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume data added to C:/Users/bsaucedo0075/Desktop/C1_combined.xlsx\n",
      "Workbook saved explicitly at C:/Users/bsaucedo0075/Desktop/C1_combined.xlsx\n",
      "Sheets available in the workbook after saving: ['T7 P4 C1', 'T7 P3 C1', 'T7 P2 C1', 'T7 P1 C1', 'T6 P4 C1', 'T6 P3 C1', 'T6 P2 C1', 'T6 P1 C1', 'T5 P4 C1', 'T5 P3 C1', 'T5 P2 C1', 'T5 P1 C1', 'T4 P4 C1', 'T4 P3 C1', 'T4 P2 C1', 'T4 P1 C1', 'T3 P4 C1', 'T3 P3 C1', 'T3 P2 C1', 'T3 P1 C1', 'T2 P4 C1', 'T2 P2 C1', 'T2 P1 C1', 'T2 P3 C1', 'T1 P3 C1', 'T1 P2 C1', 'T1 P1 C1', 'T1 P4 C1', 'T0 P4 C1', 'T0 P3 C1', 'T0 P2 C1', 'T0 P1 C1', 'C1_volume_data']\n"
     ]
    }
   ],
   "source": [
    "for sheet in excel_file.sheet_names:\n",
    "    parts = sheet.split()\n",
    "    if len(parts) != 3:\n",
    "        continue\n",
    "    time, plate, condition = parts\n",
    "    df = excel_file.parse(sheet)\n",
    "    df.columns = df.columns.astype(str).str.strip()\n",
    "    if '980' in df.columns and '900' in df.columns:\n",
    "        df['Volume'] = (df['980'] - df['900'])/ 0.0010018\n",
    "        col_name = f'{time} {plate} {condition}'\n",
    "        volume_data[col_name] = df['Volume']\n",
    "if not volume_data.empty:\n",
    "    with pd.ExcelWriter(file_path, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "        volume_data.to_excel(writer, sheet_name=f'{condition}_volume_data', index=False)\n",
    "    print(f\"Volume data added to {file_path}\")\n",
    "    \n",
    "    wb = load_workbook(file_path)\n",
    "    wb.save(file_path)\n",
    "    print(f\"Workbook saved explicitly at {file_path}\")\n",
    "\n",
    "    excel_file = pd.ExcelFile(file_path)\n",
    "    print(f\"Sheets available in the workbook after saving: {excel_file.sheet_names}\")\n",
    "\n",
    "else:\n",
    "    print(\"No volume data was added. Check column names or sheet format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e98dc7fa-9c3d-4dc2-8992-481d5242fc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path length data added to C:/Users/bsaucedo0075/Desktop/C1_combined.xlsx\n",
      "Workbook saved explicitly at C:/Users/bsaucedo0075/Desktop/C1_combined.xlsx\n",
      "Sheets available in the workbook after saving: ['T7 P4 C1', 'T7 P3 C1', 'T7 P2 C1', 'T7 P1 C1', 'T6 P4 C1', 'T6 P3 C1', 'T6 P2 C1', 'T6 P1 C1', 'T5 P4 C1', 'T5 P3 C1', 'T5 P2 C1', 'T5 P1 C1', 'T4 P4 C1', 'T4 P3 C1', 'T4 P2 C1', 'T4 P1 C1', 'T3 P4 C1', 'T3 P3 C1', 'T3 P2 C1', 'T3 P1 C1', 'T2 P4 C1', 'T2 P2 C1', 'T2 P1 C1', 'T2 P3 C1', 'T1 P3 C1', 'T1 P2 C1', 'T1 P1 C1', 'T1 P4 C1', 'T0 P4 C1', 'T0 P3 C1', 'T0 P2 C1', 'T0 P1 C1', 'C1_volume_data', 'C1_pathlength_data']\n"
     ]
    }
   ],
   "source": [
    "volume_sheet_name = f'{condition}_volume_data'\n",
    "if volume_sheet_name in excel_file.sheet_names:\n",
    "    volume_df = excel_file.parse(volume_sheet_name)\n",
    "    pathlength_df = (0.0055 * volume_df) + 0.0128\n",
    "    pathlength_df.columns = volume_df.columns\n",
    "\n",
    "    with pd.ExcelWriter(file_path, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "        pathlength_df.to_excel(writer, sheet_name=f'{condition}_pathlength_data', index=False)\n",
    "    print(f\"Path length data added to {file_path}\")\n",
    "\n",
    "    wb = load_workbook(file_path)\n",
    "    wb.save(file_path)\n",
    "    print(f\"Workbook saved explicitly at {file_path}\")\n",
    "\n",
    "    excel_file = pd.ExcelFile(file_path)\n",
    "    print(f\"Sheets available in the workbook after saving: {excel_file.sheet_names}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Volume sheet '{volume_sheet_name}' not found. Cannot calculate path length.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11b9aa82-6c33-4eb2-a708-8cb5744215ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_od_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87ab130d-87c9-46e4-951e-ff71dfd1043c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found '680' column in T7 P4 C1\n",
      "Using pathlength value of 0.321344606856896 for T7 P4 C1\n",
      "Corrected OD added to T7 P4 C1\n",
      "Found '680' column in T7 P3 C1\n",
      "Using pathlength value of 0.3268347357709192 for T7 P3 C1\n",
      "Corrected OD added to T7 P3 C1\n",
      "Found '680' column in T7 P2 C1\n",
      "Using pathlength value of 0.3317758436126271 for T7 P2 C1\n",
      "Corrected OD added to T7 P2 C1\n",
      "Found '680' column in T7 P1 C1\n",
      "Using pathlength value of 0.3235406911461577 for T7 P1 C1\n",
      "Corrected OD added to T7 P1 C1\n",
      "Found '680' column in T6 P4 C1\n",
      "Using pathlength value of 0.345501124993121 for T6 P4 C1\n",
      "Corrected OD added to T6 P4 C1\n",
      "Found '680' column in T6 P3 C1\n",
      "Using pathlength value of 0.3416580592960436 for T6 P3 C1\n",
      "Corrected OD added to T6 P3 C1\n",
      "Found '680' column in T6 P2 C1\n",
      "Using pathlength value of 0.3471481064009365 for T6 P2 C1\n",
      "Corrected OD added to T6 P2 C1\n",
      "Found '680' column in T6 P1 C1\n",
      "Using pathlength value of 0.3405600989605427 for T6 P1 C1\n",
      "Corrected OD added to T6 P1 C1\n",
      "Found '680' column in T5 P4 C1\n",
      "Using pathlength value of 0.3756967931156837 for T5 P4 C1\n",
      "Corrected OD added to T5 P4 C1\n",
      "Found '680' column in T5 P3 C1\n",
      "Using pathlength value of 0.3833829245098385 for T5 P3 C1\n",
      "Corrected OD added to T5 P3 C1\n",
      "Found '680' column in T5 P2 C1\n",
      "Using pathlength value of 0.3850299877267843 for T5 P2 C1\n",
      "Corrected OD added to T5 P2 C1\n",
      "Found '680' column in T5 P1 C1\n",
      "Using pathlength value of 0.376794835260315 for T5 P1 C1\n",
      "Corrected OD added to T5 P1 C1\n",
      "Found '680' column in T4 P4 C1\n",
      "Using pathlength value of 0.4069905033828776 for T4 P4 C1\n",
      "Corrected OD added to T4 P4 C1\n",
      "Found '680' column in T4 P3 C1\n",
      "Using pathlength value of 0.4141276137047171 for T4 P3 C1\n",
      "Corrected OD added to T4 P3 C1\n",
      "Found '680' column in T4 P2 C1\n",
      "Using pathlength value of 0.4113825901522703 for T4 P2 C1\n",
      "Corrected OD added to T4 P2 C1\n",
      "Found '680' column in T4 P1 C1\n",
      "Using pathlength value of 0.4086374847906938 for T4 P1 C1\n",
      "Corrected OD added to T4 P1 C1\n",
      "Found '680' column in T3 P4 C1\n",
      "Using pathlength value of 0.4294999583021561 for T3 P4 C1\n",
      "Corrected OD added to T3 P4 C1\n",
      "Found '680' column in T3 P3 C1\n",
      "Using pathlength value of 0.4360880475516803 for T3 P3 C1\n",
      "Corrected OD added to T3 P3 C1\n",
      "Found '680' column in T3 P2 C1\n",
      "Using pathlength value of 0.431696042591418 for T3 P2 C1\n",
      "Corrected OD added to T3 P2 C1\n",
      "Found '680' column in T3 P1 C1\n",
      "Using pathlength value of 0.4267549347497099 for T3 P1 C1\n",
      "Corrected OD added to T3 P1 C1\n",
      "Found '680' column in T2 P4 C1\n",
      "Using pathlength value of 0.4613426078325358 for T2 P4 C1\n",
      "Corrected OD added to T2 P4 C1\n",
      "Found '680' column in T2 P2 C1\n",
      "Using pathlength value of 0.4646367342664276 for T2 P2 C1\n",
      "Corrected OD added to T2 P2 C1\n",
      "Found '680' column in T2 P1 C1\n",
      "Using pathlength value of 0.4585975842800888 for T2 P1 C1\n",
      "Corrected OD added to T2 P1 C1\n",
      "Found '680' column in T2 P3 C1\n",
      "Using pathlength value of 0.4613426078325359 for T2 P3 C1\n",
      "Corrected OD added to T2 P3 C1\n",
      "Found '680' column in T1 P3 C1\n",
      "Using pathlength value of 0.5162438151636389 for T1 P3 C1\n",
      "Corrected OD added to T1 P3 C1\n",
      "Found '680' column in T1 P2 C1\n",
      "Using pathlength value of 0.5217339440776627 for T1 P2 C1\n",
      "Corrected OD added to T1 P2 C1\n",
      "Found '680' column in T1 P1 C1\n",
      "Using pathlength value of 0.5145967519466924 for T1 P1 C1\n",
      "Corrected OD added to T1 P1 C1\n",
      "Found '680' column in T1 P4 C1\n",
      "Using pathlength value of 0.5156947940913236 for T1 P4 C1\n",
      "Corrected OD added to T1 P4 C1\n",
      "Found '680' column in T0 P4 C1\n",
      "Using pathlength value of 0.5804781352967125 for T0 P4 C1\n",
      "Corrected OD added to T0 P4 C1\n",
      "Found '680' column in T0 P3 C1\n",
      "Using pathlength value of 0.587615327427682 for T0 P3 C1\n",
      "Corrected OD added to T0 P3 C1\n",
      "Found '680' column in T0 P2 C1\n",
      "Using pathlength value of 0.5821251985136578 for T0 P2 C1\n",
      "Corrected OD added to T0 P2 C1\n",
      "Found '680' column in T0 P1 C1\n",
      "Using pathlength value of 0.5716939617579269 for T0 P1 C1\n",
      "Corrected OD added to T0 P1 C1\n",
      "All corrected C1 sheets written to C:\\Users\\bsaucedo0075\\Desktop\\C1_corrected_OD_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "pathlength_df = excel_file.parse('C1_pathlength_data')\n",
    "pathlength_df.columns = pathlength_df.columns.astype(str).str.strip()\n",
    "\n",
    "corrected_od_data = {}\n",
    "\n",
    "for sheet in excel_file.sheet_names:\n",
    "    parts = sheet.split()\n",
    "    \n",
    "    if len(parts) != 3:\n",
    "        continue\n",
    "\n",
    "    time, plate, condition = parts\n",
    "\n",
    "    if condition == 'C1':\n",
    "        df = excel_file.parse(sheet)\n",
    "        df.columns = df.columns.astype(str).str.strip()\n",
    "\n",
    "        if '680' in df.columns:\n",
    "            print(f\"Found '680' column in {sheet}\")\n",
    "            \n",
    "            pathlength_column_name = f'{time} {plate} {condition}'\n",
    "            \n",
    "            if pathlength_column_name in pathlength_df.columns:\n",
    "                pathlength_value = pathlength_df[pathlength_column_name].iloc[0]  # Assuming single value per column\n",
    "                print(f\"Using pathlength value of {pathlength_value} for {pathlength_column_name}\")\n",
    "                \n",
    "                df['Corrected_OD'] = df['680'] / pathlength_value\n",
    "                \n",
    "                corrected_od_data[sheet] = df[['680', 'Corrected_OD']]  # Save just '680' and 'Corrected_OD'\n",
    "\n",
    "                print(f\"Corrected OD added to {sheet}\")\n",
    "            else:\n",
    "                print(f\"Pathlength data for {pathlength_column_name} not found.\")\n",
    "        else:\n",
    "            print(f\"'680' column not found in {sheet}. Skipping.\")\n",
    "    else:\n",
    "        print(f\"Skipping sheet {sheet} because it is not in 'C1' condition.\")\n",
    "\n",
    "# Write all corrected C1 sheets to a single new Excel file on the desktop\n",
    "if corrected_od_data:\n",
    "    desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "    output_file = os.path.join(desktop_path, \"C1_corrected_OD_data.xlsx\")\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        for sheet_name, df in corrected_od_data.items():\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    print(f\"All corrected C1 sheets written to {output_file}\")\n",
    "else:\n",
    "    print(\"No corrected OD data was added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4dec67e1-25e7-4f77-992c-7a1c6d03fbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found '680' column in T7 P4 C1\n",
      "Using pathlength value of 0.321344606856896 for T7 P4 C1\n",
      "Log_FC_Positive calculated for T7 P4 C1\n",
      "Found '680' column in T7 P3 C1\n",
      "Using pathlength value of 0.3268347357709192 for T7 P3 C1\n",
      "Log_FC_Positive calculated for T7 P3 C1\n",
      "Found '680' column in T7 P2 C1\n",
      "Using pathlength value of 0.3317758436126271 for T7 P2 C1\n",
      "Log_FC_Positive calculated for T7 P2 C1\n",
      "Found '680' column in T7 P1 C1\n",
      "Using pathlength value of 0.3235406911461577 for T7 P1 C1\n",
      "Log_FC_Positive calculated for T7 P1 C1\n",
      "Found '680' column in T6 P4 C1\n",
      "Using pathlength value of 0.345501124993121 for T6 P4 C1\n",
      "Log_FC_Positive calculated for T6 P4 C1\n",
      "Found '680' column in T6 P3 C1\n",
      "Using pathlength value of 0.3416580592960436 for T6 P3 C1\n",
      "Log_FC_Positive calculated for T6 P3 C1\n",
      "Found '680' column in T6 P2 C1\n",
      "Using pathlength value of 0.3471481064009365 for T6 P2 C1\n",
      "Log_FC_Positive calculated for T6 P2 C1\n",
      "Found '680' column in T6 P1 C1\n",
      "Using pathlength value of 0.3405600989605427 for T6 P1 C1\n",
      "Log_FC_Positive calculated for T6 P1 C1\n",
      "Found '680' column in T5 P4 C1\n",
      "Using pathlength value of 0.3756967931156837 for T5 P4 C1\n",
      "Log_FC_Positive calculated for T5 P4 C1\n",
      "Found '680' column in T5 P3 C1\n",
      "Using pathlength value of 0.3833829245098385 for T5 P3 C1\n",
      "Log_FC_Positive calculated for T5 P3 C1\n",
      "Found '680' column in T5 P2 C1\n",
      "Using pathlength value of 0.3850299877267843 for T5 P2 C1\n",
      "Log_FC_Positive calculated for T5 P2 C1\n",
      "Found '680' column in T5 P1 C1\n",
      "Using pathlength value of 0.376794835260315 for T5 P1 C1\n",
      "Log_FC_Positive calculated for T5 P1 C1\n",
      "Found '680' column in T4 P4 C1\n",
      "Using pathlength value of 0.4069905033828776 for T4 P4 C1\n",
      "Log_FC_Positive calculated for T4 P4 C1\n",
      "Found '680' column in T4 P3 C1\n",
      "Using pathlength value of 0.4141276137047171 for T4 P3 C1\n",
      "Log_FC_Positive calculated for T4 P3 C1\n",
      "Found '680' column in T4 P2 C1\n",
      "Using pathlength value of 0.4113825901522703 for T4 P2 C1\n",
      "Log_FC_Positive calculated for T4 P2 C1\n",
      "Found '680' column in T4 P1 C1\n",
      "Using pathlength value of 0.4086374847906938 for T4 P1 C1\n",
      "Log_FC_Positive calculated for T4 P1 C1\n",
      "Found '680' column in T3 P4 C1\n",
      "Using pathlength value of 0.4294999583021561 for T3 P4 C1\n",
      "Log_FC_Positive calculated for T3 P4 C1\n",
      "Found '680' column in T3 P3 C1\n",
      "Using pathlength value of 0.4360880475516803 for T3 P3 C1\n",
      "Log_FC_Positive calculated for T3 P3 C1\n",
      "Found '680' column in T3 P2 C1\n",
      "Using pathlength value of 0.431696042591418 for T3 P2 C1\n",
      "Log_FC_Positive calculated for T3 P2 C1\n",
      "Found '680' column in T3 P1 C1\n",
      "Using pathlength value of 0.4267549347497099 for T3 P1 C1\n",
      "Log_FC_Positive calculated for T3 P1 C1\n",
      "Found '680' column in T2 P4 C1\n",
      "Using pathlength value of 0.4613426078325358 for T2 P4 C1\n",
      "Log_FC_Positive calculated for T2 P4 C1\n",
      "Found '680' column in T2 P2 C1\n",
      "Using pathlength value of 0.4646367342664276 for T2 P2 C1\n",
      "Log_FC_Positive calculated for T2 P2 C1\n",
      "Found '680' column in T2 P1 C1\n",
      "Using pathlength value of 0.4585975842800888 for T2 P1 C1\n",
      "Log_FC_Positive calculated for T2 P1 C1\n",
      "Found '680' column in T2 P3 C1\n",
      "Using pathlength value of 0.4613426078325359 for T2 P3 C1\n",
      "Log_FC_Positive calculated for T2 P3 C1\n",
      "Found '680' column in T1 P3 C1\n",
      "Using pathlength value of 0.5162438151636389 for T1 P3 C1\n",
      "Log_FC_Positive calculated for T1 P3 C1\n",
      "Found '680' column in T1 P2 C1\n",
      "Using pathlength value of 0.5217339440776627 for T1 P2 C1\n",
      "Log_FC_Positive calculated for T1 P2 C1\n",
      "Found '680' column in T1 P1 C1\n",
      "Using pathlength value of 0.5145967519466924 for T1 P1 C1\n",
      "Log_FC_Positive calculated for T1 P1 C1\n",
      "Found '680' column in T1 P4 C1\n",
      "Using pathlength value of 0.5156947940913236 for T1 P4 C1\n",
      "Log_FC_Positive calculated for T1 P4 C1\n",
      "Found '680' column in T0 P4 C1\n",
      "Using pathlength value of 0.5804781352967125 for T0 P4 C1\n",
      "Log_FC_Positive calculated for T0 P4 C1\n",
      "Found '680' column in T0 P3 C1\n",
      "Using pathlength value of 0.587615327427682 for T0 P3 C1\n",
      "Log_FC_Positive calculated for T0 P3 C1\n",
      "Found '680' column in T0 P2 C1\n",
      "Using pathlength value of 0.5821251985136578 for T0 P2 C1\n",
      "Log_FC_Positive calculated for T0 P2 C1\n",
      "Found '680' column in T0 P1 C1\n",
      "Using pathlength value of 0.5716939617579269 for T0 P1 C1\n",
      "Log_FC_Positive calculated for T0 P1 C1\n",
      "All log fold change data written to C:\\Users\\bsaucedo0075\\Desktop\\C1_natural_log_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "pathlength_df = excel_file.parse('C1_pathlength_data')\n",
    "pathlength_df.columns = pathlength_df.columns.astype(str).str.strip()\n",
    "\n",
    "corrected_od_data = {}\n",
    "log_fc_data = {}\n",
    "\n",
    "for sheet in excel_file.sheet_names:\n",
    "    parts = sheet.split()\n",
    "    \n",
    "    if len(parts) != 3:\n",
    "        continue\n",
    "\n",
    "    time, plate, condition = parts\n",
    "\n",
    "    if condition == 'C1':\n",
    "        df = excel_file.parse(sheet)\n",
    "        df.columns = df.columns.astype(str).str.strip()\n",
    "\n",
    "        if '680' in df.columns:\n",
    "            print(f\"Found '680' column in {sheet}\")\n",
    "            \n",
    "            pathlength_column_name = f'{time} {plate} {condition}'\n",
    "            \n",
    "            if pathlength_column_name in pathlength_df.columns:\n",
    "                pathlength_value = pathlength_df[pathlength_column_name].iloc[0]\n",
    "                print(f\"Using pathlength value of {pathlength_value} for {pathlength_column_name}\")\n",
    "                \n",
    "                df['Corrected_OD'] = df['680'] / pathlength_value\n",
    "                df['680'] = pd.to_numeric(df['680'], errors='coerce')\n",
    "                df['Corrected_OD'] = pd.to_numeric(df['Corrected_OD'], errors='coerce')\n",
    "\n",
    "                baseline = df['Corrected_OD'].iloc[0]\n",
    "                df['Log_FC_Positive'] = np.log(df['Corrected_OD'] / baseline)\n",
    "                df['Log_FC_Positive'] = df['Log_FC_Positive'].apply(lambda x: x if x >= 0 else 0)\n",
    "\n",
    "                # Only store what's needed for the new file\n",
    "                log_fc_data[sheet] = df[['Corrected_OD', 'Log_FC_Positive']]\n",
    "\n",
    "                print(f\"Log_FC_Positive calculated for {sheet}\")\n",
    "            else:\n",
    "                print(f\"Pathlength data for {pathlength_column_name} not found.\")\n",
    "        else:\n",
    "            print(f\"'680' column not found in {sheet}. Skipping.\")\n",
    "    else:\n",
    "        print(f\"Skipping sheet {sheet} because it is not in 'C1' condition.\")\n",
    "\n",
    "# Save natural log fold change data only\n",
    "if log_fc_data:\n",
    "    desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "    log_file = os.path.join(desktop_path, \"C1_natural_log_data.xlsx\")\n",
    "    with pd.ExcelWriter(log_file, engine='openpyxl') as writer:\n",
    "        for sheet_name, df in log_fc_data.items():\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    print(f\"All log fold change data written to {log_file}\")\n",
    "else:\n",
    "    print(\"No log fold change data was added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99abe1b-0adf-47e3-b84e-c1f365ea2576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f4928-18aa-497f-bb93-58a5d6f83d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
